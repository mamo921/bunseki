import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import io
from datetime import datetime
import json
import re
import bcrypt
import matplotlib.font_manager as fm # ãƒ•ã‚©ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os

# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜éšå±¤ã« static ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å ´åˆ
font_path = os.path.join(os.path.dirname(__file__), "static", "NotoSansJP-VariableFont_wght.ttf")
# çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›ï¼ˆã“ã‚ŒãŒä¸€ç•ªå®‰å…¨ï¼ï¼‰
font_path = os.path.abspath(font_path)

if os.path.exists(font_path):
    font_prop = fm.FontProperties(fname=font_path)
    plt.rcParams["font.family"] = font_prop.get_name()
    japanese_font_available = True
else:
    font_prop = None
    japanese_font_available = False
    st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•ã®ãƒ©ãƒ™ãƒ«ãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# matplotlibã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

# ãƒ•ã‚©ãƒ³ãƒˆèª­ã¿è¾¼ã¿ãƒã‚§ãƒƒã‚¯
if os.path.exists(font_path):
    #font_prop = fm.FontProperties(fname=font_path)
    #font_name = font_prop.get_name()
    #plt.rcParams['font.family'] = font_name  # â† matplotlib å…¨ä½“ã«å¼·åˆ¶åæ˜ ï¼
    #japanese_font_available = True
    #st.info(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ '{font_name}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    pass
else:
    font_prop = None
    japanese_font_available = False
    st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•ã®ãƒ©ãƒ™ãƒ«ãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# matplotlib ã®ãƒã‚¤ãƒŠã‚¹è¨˜å·æ–‡å­—åŒ–ã‘å¯¾ç­–
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

# UIãƒ†ã‚­ã‚¹ãƒˆã¯å¸¸ã«æ—¥æœ¬èª
def get_localized_text(jp_text): # è‹±èªå¼•æ•°ã‚’å‰Šé™¤
    return jp_text

# ã‚°ãƒ©ãƒ•ãƒ†ã‚­ã‚¹ãƒˆã¯æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒã‚ã‚Œã°æ—¥æœ¬èªã€ãªã‘ã‚Œã°è‹±èª
def get_graph_text(jp_text): # è‹±èªå¼•æ•°ã‚’å‰Šé™¤
    return jp_text if japanese_font_available else "" # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒãªã„å ´åˆã€ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title=get_localized_text("VRã‚¤ãƒ™ãƒ³ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«"), layout="wide")

# --- èªè¨¼é–¢é€£ã®é–¢æ•° ---
# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®æ¤œè¨¼
def verify_password(password, hashed_password):
    return bcrypt.checkpw(password.encode(), hashed_password.encode())

# secrets.tomlã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
def load_users_from_secrets():
    users = []
    try:
        for _, user in st.secrets["users"].items():
            # valueã¯è¾æ›¸ã¾ãŸã¯JSONæ–‡å­—åˆ—ã®å ´åˆãŒã‚ã‚‹ã®ã§å¯¾å¿œ
            if isinstance(user, str):
                user = json.loads(user)
            users.append(user)
    except Exception as e:
        st.error(get_localized_text(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"))
        st.stop()
    return users

# ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã®è¡¨ç¤º
def login_form():
    st.subheader(get_localized_text("ãƒ­ã‚°ã‚¤ãƒ³"))

    user_data = load_users_from_secrets()

    with st.form("login_form"):
        username_input = st.text_input(get_localized_text("ãƒ¦ãƒ¼ã‚¶ãƒ¼å"))
        password_input = st.text_input(get_localized_text("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰"), type="password")
        submitted = st.form_submit_button(get_localized_text("ãƒ­ã‚°ã‚¤ãƒ³"))

    if submitted:
        found_user = False
        for user in user_data:
            if username_input == user["username"]:
                found_user = True
                if verify_password(password_input, user["password_hash"]):
                    st.session_state["logged_in"] = True
                    st.session_state["username"] = user["username"]
                    st.success(get_localized_text("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼"))
                    st.rerun()
                else:
                    st.error(get_localized_text("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚"))
                break
        if not found_user:
            st.error(get_localized_text("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"))

def show_main_app():
    df = st.session_state.get("current_data", None)
    if df is None:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    # ğŸ”½ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ã†ã€‚ãªã‘ã‚Œã°å…¨ä½“ã‚’ä½¿ã†
    df_filtered = st.session_state.get("dfmain", df)

# --- ã‚¢ãƒ—ãƒªæœ¬ä½“ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•° (v1.0.0.py ã‹ã‚‰ã®ç§»è¡Œ) ---

class SessionManager:
    @staticmethod
    def initialize():
        session_vars = {
            'upload_files': [],
            'template_store': [],
            'analysis_log': [],
            'comparison_template': {},
            'current_data': None,
            'selected_teams': None, # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®çŠ¶æ…‹ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«Noneã‚’è¨±å®¹
            'date_range': [None, None],
            'analysis_count': 0,
            'heatmap_count': 0,
            'trend_count': 0,
            'ranking_count': 0,
            'dfmain': None,
            'uploaded_file_processed': False,
            'num_uploaders': 1,
            'previous_files_hash': None
        }
        
        for var, default in session_vars.items():
            if var not in st.session_state:
                st.session_state[var] = default

class DataProcessor:
    @staticmethod
    def safe_read_csv(file):
        try:
            df = pd.read_csv(
                file,
                encoding='utf-8-sig',
                on_bad_lines='warn',
            )
            return df, None
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(
                    file,
                    encoding='cp932',
                    on_bad_lines='warn',
                )
                return df, None
            except Exception as e:
                return None, get_localized_text(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            return None, get_localized_text(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

    @staticmethod
    def process_dataframe(df):
        if df is None:
            return None
            
        if 'å®Ÿæ–½æ—¥' in df.columns:
            # å®Ÿæ–½æ—¥åˆ—ã®å¤‰æ›ã¨NaNãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
            initial_nan_count = df['å®Ÿæ–½æ—¥'].isnull().sum()
            df['å®Ÿæ–½æ—¥'] = pd.to_datetime(df['å®Ÿæ–½æ—¥'], errors='coerce')
            # æ™‚é–“éƒ¨åˆ†ã‚’å‰Šé™¤ã—ã€æ—¥ä»˜ã®ã¿ã«ã™ã‚‹ï¼ˆ.dt.normalize()ã‚’è¿½åŠ ï¼‰
            df['å®Ÿæ–½æ—¥'] = df['å®Ÿæ–½æ—¥'].dt.normalize().dt.date 

            nan_after_coerce = df['å®Ÿæ–½æ—¥'].isnull().sum()
            
            if nan_after_coerce > initial_nan_count:
                newly_coerced_nan_percentage = (nan_after_coerce - initial_nan_count) / len(df) * 100
                if newly_coerced_nan_percentage > 10: # ä¾‹ãˆã°10%ä»¥ä¸Šã®å€¤ãŒç„¡åŠ¹ã«ãªã£ãŸå ´åˆã«è­¦å‘Š
                    st.warning(get_localized_text(
                        f"ã€Œå®Ÿæ–½æ—¥ã€åˆ—ã®{newly_coerced_nan_percentage:.1f}%ãŒæ—¥ä»˜ã¨ã—ã¦èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…ƒã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    ))

        numeric_cols = ['ç”³è¾¼æ•°', 'å‚åŠ è€…æ•°', 'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°', 'å®£ä¼å›æ•°', 'æº€è¶³å›ç­”']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce') 
        
        if all(col in df.columns for col in ['å‚åŠ è€…æ•°', 'ç”³è¾¼æ•°']):
            df['å‚åŠ ç‡(%)'] = (df['å‚åŠ è€…æ•°'] / df['ç”³è¾¼æ•°']) * 100
        if all(col in df.columns for col in ['æº€è¶³å›ç­”', 'å‚åŠ è€…æ•°']):
            df['æº€è¶³ç‡(%)'] = (df['æº€è¶³å›ç­”'] / df['å‚åŠ è€…æ•°']) * 100
        if all(col in df.columns for col in ['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°', 'å‚åŠ è€…æ•°']):
            df['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡'] = df['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°'] / df['å‚åŠ è€…æ•°']
        
        return df

    @staticmethod
    def expand_time_slots(df):
        if 'æ™‚é–“å¸¯' in df.columns:
            df['æ™‚é–“å¸¯'] = df['æ™‚é–“å¸¯'].astype(str)
            df['æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ'] = df['æ™‚é–“å¸¯'].str.split('ãƒ»')
            df = df.explode('æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ').reset_index(drop=True) # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒªã‚»ãƒƒãƒˆã‚’è¿½åŠ 
            df['æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ'] = df['æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ'].str.strip()
        return df

# ãƒ¡ã‚¤ãƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤º (v1.0.0.py ã® main é–¢æ•°ã‚’ show_main_app ã«ãƒªãƒãƒ¼ãƒ )
def show_main_app():
    # This style block should be removed or commented out as it might interfere with font settings
    # st.markdown("""
    # <style>
    # @font-face {
    # font-family: 'Noto Sans JP';
    # src: url('/static/NotoSansJP-Thin.woff2') format('woff2');
    # }
    # body, div, p, span, input, label {
    # font-family: 'Noto Sans JP', sans-serif !important;
    # }
    # </style>
    # """, unsafe_allow_html=True)

    st.title(get_localized_text("VRã‚¤ãƒ™ãƒ³ãƒˆåˆ†æã‚¢ãƒ—ãƒª"))

    SessionManager.initialize()

    df_current = st.session_state.get("current_data")
    df_main = st.session_state.get("dfmain")

    if "df_filtered" not in st.session_state or st.session_state["df_filtered"] is None or getattr(st.session_state["df_filtered"], "empty", True):
        if df_current is not None and not df_current.empty:
            st.session_state["df_filtered"] = df_current.copy()
        elif df_main is not None and not df_main.empty:
            st.session_state["df_filtered"] = df_main.copy()

    # ğŸ”§ df_filtered ã‚’å¸¸ã« current_data ã‹ã‚‰å†ç”Ÿæˆï¼ˆç©ºã ã£ãŸã‚‰ dfmain ã‹ã‚‰ï¼‰
    if "df_filtered" not in st.session_state or st.session_state["df_filtered"] is None or st.session_state["df_filtered"] is ... or getattr(st.session_state["df_filtered"], "empty", True):
        df_candidate = st.session_state.get("current_data") or st.session_state.get("dfmain")
        if df_candidate is not None and not df_candidate.empty:
            st.session_state["df_filtered"] = df_candidate.copy()

    # ğŸ”§ df_filtered ã‚’å®Œå…¨ã«åŒæœŸã•ã›ã¦ãŠã
    df_filtered = st.session_state.get("current_data")

    # fallbackï¼ˆã¾ã current_dataãŒNoneãªã‚‰dfmainã‚’ä½¿ã†ï¼‰
    if df_filtered is None or df_filtered.empty:
        df_filtered = st.session_state.get("dfmain")

    # ğŸ” ãƒ‡ãƒ¼ã‚¿ãŒå‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã¯ True ã ãŒã€ä¸­èº«ãŒ None or ç©ºãªã‚‰å†å‡¦ç†
    if (
        st.session_state.get("upload_files") and
        st.session_state.get("uploaded_file_processed") and
        (
            st.session_state.get("dfmain") is None or
            st.session_state["dfmain"].empty or
            st.session_state.get("current_data") is None or
            st.session_state["current_data"].empty
        )
    ):
        st.session_state["uploaded_file_processed"] = False
        st.rerun()

    df_filtered = None  # â† æœ€åˆã«å®šç¾©ã—ã¦ãŠãï¼ï¼ˆã“ã‚ŒãŒé‡è¦ï¼‰

    with st.sidebar:
        st.markdown(get_localized_text("## ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š"))
        st.markdown("---")

        dfmain_for_sidebar = st.session_state.get('dfmain')

        if dfmain_for_sidebar is not None and not dfmain_for_sidebar.empty:
            df_filtered = dfmain_for_sidebar.copy()

            # ğŸ‘¥ æ‹…å½“ãƒãƒ¼ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if 'æ‹…å½“ãƒãƒ¼ãƒ ' in df_filtered.columns:
                teams = sorted(df_filtered['æ‹…å½“ãƒãƒ¼ãƒ '].dropna().unique().tolist())  # å¿…ãš list åŒ–ï¼

                # å®‰å…¨ã«å–å¾—ï¼ˆlist ã˜ã‚ƒãªã‹ã£ãŸã‚‰åˆæœŸåŒ–ï¼‰
                previous_selection = st.session_state.get("selected_teams", [])
                if not isinstance(previous_selection, list):
                    previous_selection = []

                # é¸æŠè‚¢ã«ã‚ã‚‹ã‚‚ã®ã ã‘æ®‹ã™
                valid_selection = [t for t in previous_selection if t in teams]

                # é¸æŠè‚¢ãŒå…¨éƒ¨æ¶ˆãˆã¦ã„ãŸã‚‰å…¨é¸æŠã§å¾©æ—§
                if not valid_selection:
                    valid_selection = teams.copy()

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state["selected_teams"] = valid_selection

                # multiselect è¡¨ç¤º
                st.multiselect(
                    get_localized_text("ğŸ‘¥ æ‹…å½“ãƒãƒ¼ãƒ "),
                    options=teams,
                    default=valid_selection,
                    key="selected_teams"
                )

                # å®Ÿéš›ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
                if st.session_state['selected_teams']:
                    df_filtered = df_filtered[df_filtered['æ‹…å½“ãƒãƒ¼ãƒ '].isin(st.session_state['selected_teams'])]
                else:
                    st.warning(get_localized_text("æ‹…å½“ãƒãƒ¼ãƒ ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…¨ã¦ã®æ‹…å½“ãƒãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"))

            if 'å®Ÿæ–½æ—¥' in df_filtered.columns:
                # dt.dateã«å¤‰æ›ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãã®ã¾ã¾ä½¿ç”¨
                valid_dates = df_filtered['å®Ÿæ–½æ—¥'].dropna()
                if not valid_dates.empty:
                    # Pythonã®dateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯min()/max()ã§ç›´æ¥æ¯”è¼ƒå¯èƒ½
                    min_date = min(valid_dates)
                    max_date = max(valid_dates)
                    
                    default_date_range = [min_date, max_date] if min_date <= max_date else [min_date, min_date]
                    date_range = st.date_input(get_localized_text("ğŸ“… å®Ÿæ–½æ—¥ã®ç¯„å›²"), value=default_date_range)
                    
                    if isinstance(date_range, (list, tuple)) and len(date_range) == 2:
                        start, end = date_range[0], date_range[1]
                        df_filtered = df_filtered[
                            (df_filtered['å®Ÿæ–½æ—¥'] >= start) & 
                            (df_filtered['å®Ÿæ–½æ—¥'] <= end)
                        ]
                else:
                    st.warning(get_localized_text("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
            
            st.session_state.current_data = df_filtered

        else:
            st.info(get_localized_text("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"))

    tabs = st.tabs([
        get_localized_text("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†"),
        get_localized_text("ğŸ“ˆ åˆ†æãƒ»æ¯”è¼ƒ"),
        get_localized_text("ğŸ“Š ã‚¯ãƒ­ã‚¹é›†è¨ˆ"),
        get_localized_text("ğŸ•’ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"),
        get_localized_text("ğŸ“‰ æ™‚ç³»åˆ—"),
        get_localized_text("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°"),
        get_localized_text("ğŸ“‹ è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆ")
    ])

    title_font = {
        'fontsize': 14,
        'fontweight': 'bold'
    }

    with tabs[0]:
        st.header(get_localized_text("ğŸ“ åˆ†æå¯¾è±¡CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"))
        
        col1, col2 = st.columns([2, 1])
        with col1:
            all_uploaded_files_current_run = [] 
            uploader_objects = [] 
            last_uploaded_idx = -1 

            for i in range(st.session_state.num_uploaders):
                label = get_localized_text("CSVãƒ•ã‚¡ã‚¤ãƒ« (å¿…é ˆ)") if i == 0 else get_localized_text(f"è¿½åŠ ã®CSVãƒ•ã‚¡ã‚¤ãƒ« (ã‚ªãƒ—ã‚·ãƒ§ãƒ³ {i})")
                file_obj = st.file_uploader(
                    label,
                    type="csv",
                    key=f"csv_upload_{i}"
                )
                uploader_objects.append(file_obj)
                
                if file_obj is not None:
                    last_uploaded_idx = i
                    all_uploaded_files_current_run.append(file_obj)

            new_num_uploaders = st.session_state.num_uploaders

            if last_uploaded_idx != -1:
                target_num_uploaders = last_uploaded_idx + 2
                new_num_uploaders = max(new_num_uploaders, target_num_uploaders)
            else:
                new_num_uploaders = 1
            
            if last_uploaded_idx != -1 and st.session_state.num_uploaders > (last_uploaded_idx + 2):
                new_num_uploaders = last_uploaded_idx + 2
            elif last_uploaded_idx == -1 and st.session_state.num_uploaders > 1:
                new_num_uploaders = 1

            if new_num_uploaders != st.session_state.num_uploaders:
                st.session_state.num_uploaders = new_num_uploaders
                st.rerun()

            current_files_hash = hash(tuple((f.name, f.size) for f in all_uploaded_files_current_run if f is not None))
            previous_files_hash = st.session_state.get('previous_files_hash', None)

            files_changed = (current_files_hash != previous_files_hash)
            
            if files_changed and all_uploaded_files_current_run:
                st.session_state.upload_files = all_uploaded_files_current_run
                st.session_state.uploaded_file_processed = False
                st.session_state.previous_files_hash = current_files_hash
                st.rerun()

            # ğŸ”½ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã€å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ãŒTrueã§ã‚‚dfmainãŒNoneãªã‚‰å†å‡¦ç†ã™ã‚‹
            if (
                st.session_state.upload_files and 
                st.session_state.uploaded_file_processed and 
                (st.session_state.dfmain is None or st.session_state.current_data is None)
            ):
                st.session_state.uploaded_file_processed = False
                st.rerun()

            if st.session_state.upload_files and not st.session_state.uploaded_file_processed:
                uploaded_dfs_temp = []
                for f in st.session_state.upload_files:
                    f.seek(0)
                    df_t, error = DataProcessor.safe_read_csv(f)
                    if error:
                        st.error(get_localized_text(f"ãƒ•ã‚¡ã‚¤ãƒ« {f.name}: {error}"))
                    else:
                        df_t = DataProcessor.process_dataframe(df_t)
                        if df_t is not None:
                            uploaded_dfs_temp.append(df_t)

                if uploaded_dfs_temp:
                    df_combined = pd.concat(uploaded_dfs_temp, ignore_index=True).drop_duplicates()
                    df_combined = DataProcessor.expand_time_slots(df_combined)
                    st.session_state['dfmain'] = df_combined
                    st.session_state.current_data = df_combined
                    st.session_state.uploaded_file_processed = True

                    numeric_cols_for_check = ['ç”³è¾¼æ•°', 'å‚åŠ è€…æ•°', 'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°', 'å®£ä¼å›æ•°', 'æº€è¶³å›ç­”']
                    high_nan_cols = []
                    for col in numeric_cols_for_check:
                        if col in df_combined.columns:
                            nan_percentage = df_combined[col].isnull().sum() / len(df_combined) * 100
                            if nan_percentage > 50: 
                                high_nan_cols.append(f"{col} ({nan_percentage:.1f}%)")
                    if high_nan_cols:
                        st.warning(get_localized_text(
                            f"ä»¥ä¸‹ã®æ•°å€¤åˆ—ã§é«˜ã„æ¬ æç‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {', '.join(high_nan_cols)}ã€‚\n"
                            "ã“ã‚Œã¯ã€å…ƒã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è©²å½“åˆ—ã«æ•°å€¤ä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤šãå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                            "ãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºæ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                        ))
                else:
                    st.session_state['dfmain'] = None
                    st.session_state.current_data = None
                    st.session_state.uploaded_file_processed = True
            
        df_display = st.session_state.get('current_data')
        if df_display is None or df_display.empty:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
        else:
            if st.session_state.upload_files:
                with col2:
                    st.markdown(get_localized_text("### ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±"))
                    for i, f in enumerate(all_uploaded_files_current_run, 1):
                        if f is not None:
                            display_name = f.name if hasattr(f, 'name') else get_localized_text(f"ãƒ•ã‚¡ã‚¤ãƒ« {i}")
                            st.info(get_localized_text(f"ãƒ•ã‚¡ã‚¤ãƒ« {i}: {display_name}"))

                if len(st.session_state.upload_files) > 1: 
                    st.markdown(get_localized_text("### ğŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆçµæœ"))
                    total_rows_before = 0
                    for f in st.session_state.upload_files:
                        f.seek(0)
                        temp_df, _ = DataProcessor.safe_read_csv(f)
                        if temp_df is not None:
                            total_rows_before += len(temp_df)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(get_localized_text("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿æ•°"), f"{total_rows_before}{get_localized_text('è¡Œ')}")
                    with col2:
                        st.metric(get_localized_text("çµ±åˆå¾Œã®ãƒ‡ãƒ¼ã‚¿æ•°"), f"{len(df_display)}{get_localized_text('è¡Œ')}")
                    with col3:
                        removed_rows = total_rows_before - len(df_display)
                        if removed_rows > 0:
                            st.metric(get_localized_text("é‡è¤‡å‰Šé™¤"), f"{removed_rows}{get_localized_text('è¡Œ')}")
                            st.info(get_localized_text(
                                f"â€» {removed_rows}è¡Œã®é‡è¤‡ï¼ˆå…¨ã¦ã®åˆ—ãŒå®Œå…¨ã«ä¸€è‡´ã™ã‚‹è¡Œï¼‰ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"
                            ))
                else:
                    st.info(get_localized_text(f"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ{len(df_display)}è¡Œï¼‰ã‚’å‡¦ç†ã—ã¾ã™"))

            st.markdown(get_localized_text("### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"))
            preview_rows = st.number_input(
                get_localized_text("è¡¨ç¤ºã™ã‚‹è¡Œæ•°ï¼ˆ0ã§å…¨è¡Œè¡¨ç¤ºï¼‰"),
                min_value=0,
                max_value=len(df_display),
                value=5
            )
            
            if preview_rows == 0:
                st.dataframe(df_display, use_container_width=True)
            else:
                st.dataframe(df_display.head(preview_rows), use_container_width=True)

            st.markdown(get_localized_text("### ğŸ“‹ åˆ—æƒ…å ±"))
            col_info = pd.DataFrame({
                get_localized_text('ãƒ‡ãƒ¼ã‚¿å‹'): df_display.dtypes,
                get_localized_text('æ¬ æå€¤æ•°'): df_display.isnull().sum(),
                get_localized_text('æ¬ æç‡(%)'): (df_display.isnull().sum() / len(df_display) * 100).round(2),
                get_localized_text('ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°'): df_display.nunique(),
            })
            st.dataframe(col_info)

            st.markdown(get_localized_text("### ğŸ“Š åŸºæœ¬çµ±è¨ˆé‡"))
            numeric_cols = df_display.select_dtypes(include=['int64', 'float64']).columns
            if not numeric_cols.empty:
                stats_df = df_display[numeric_cols].describe().T

                rename_map = {
                    "count": get_localized_text("ãƒ‡ãƒ¼ã‚¿æ•°"),
                    "mean": get_localized_text("å¹³å‡"),
                    "std": get_localized_text("æ¨™æº–åå·®"),
                    "min": get_localized_text("æœ€å°å€¤"),
                    "25%": "25%",
                    "50%": get_localized_text("ä¸­å¤®å€¤"),
                    "75%": "75%",
                    "max": get_localized_text("æœ€å¤§å€¤")
                }

                stats_df = stats_df.rename(columns=rename_map)
                st.dataframe(stats_df)


            st.markdown(get_localized_text("### ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ—ã®å†…è¨³"))
            category_cols = df_display.select_dtypes(include=['object']).columns
            if not category_cols.empty:
                selected_col = st.selectbox(get_localized_text("ç¢ºèªã™ã‚‹åˆ—ã‚’é¸æŠ"), category_cols)
                value_counts = df_display[selected_col].value_counts()

                fig, ax = plt.subplots()
                if df_filtered is not None and selected_col in df_filtered.columns:
                    sns.countplot(
                        x=selected_col,
                        data=df_filtered,
                        order=df_filtered[selected_col].value_counts().index,
                        ax=ax
                    )
                else:
                    st.warning("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„ã‹ã€æŒ‡å®šã•ã‚ŒãŸåˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")

                # ğŸ”½ xè»¸ã®ãƒ©ãƒ™ãƒ«ã‚¿ã‚¤ãƒˆãƒ«ã«æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨ï¼ˆã“ã‚ŒãŒãªã„ã¨è±†è…ã«ãªã‚‹ï¼‰
                ax.set_xlabel(get_graph_text(str(selected_col)), fontproperties=font_prop)

                # æç”»ï¼ˆtickãŒä½œã‚‰ã‚ŒãŸå¾Œï¼‰ã‚’å¼·åˆ¶å®Ÿè¡Œ
                plt.draw()

                # xè»¸ãƒ©ãƒ™ãƒ«ã«ãƒ•ã‚©ãƒ³ãƒˆã‚’å€‹åˆ¥ã«é©ç”¨
                for label in ax.get_xticklabels():
                    label.set_fontproperties(font_prop)

                # å¿µã®ãŸã‚ tight_layout
                plt.tight_layout()

                st.pyplot(fig)

                # ã“ã“ã‹ã‚‰è¿½åŠ ï¼štickãƒ©ãƒ™ãƒ«ã«æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨
                plt.draw()
                for label in ax.get_xticklabels():
                    label.set_fontproperties(font_prop)

                # ã‚¿ã‚¤ãƒˆãƒ«ãƒ»è»¸ãƒ©ãƒ™ãƒ«
                ax.set_title(get_graph_text(f"{selected_col}ã®å€¤ã‚«ã‚¦ãƒ³ãƒˆ"), fontproperties=font_prop, **title_font)
                ax.set_xlabel(get_graph_text(str(selected_col)), fontproperties=font_prop)
                ax.set_ylabel(get_graph_text("ã‚«ã‚¦ãƒ³ãƒˆ"), fontproperties=font_prop)

                # âœ… xè»¸ã®Tickãƒ©ãƒ™ãƒ«ã‚’å®Œå…¨ã«å†æç”»ã™ã‚‹
                xtick_labels = [tick.get_text() for tick in ax.get_xticklabels()]

                # yè»¸ã‚‚å¿µã®ãŸã‚å†è¨­å®šï¼ˆãªãã¦ã‚‚ã„ã„ã‘ã©ï¼‰
                ytick_labels = [tick.get_text() for tick in ax.get_yticklabels()]

                # è¡¨ç¤º
                st.pyplot(fig)


                for label in ax.get_xticklabels():
                    label.set_fontproperties(font_prop)
                for label in ax.get_yticklabels():
                    label.set_fontproperties(font_prop)
                
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)

    with tabs[1]:
        st.header(get_localized_text("ğŸ“ˆ åˆ†æãƒ»æ¯”è¼ƒ"))
        
        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()
            
            col1, col2 = st.columns(2)
            with col1:
                num_cols = df.select_dtypes(include='number').columns.tolist()
                cat_cols = df.select_dtypes(include='object').columns.tolist()
                
                if not num_cols:
                    st.warning(get_localized_text("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                    st.stop()
                if not cat_cols:
                    st.warning(get_localized_text("ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                    st.stop()

                target_num = st.selectbox(get_localized_text("åˆ†æå¯¾è±¡ï¼ˆæ•°å€¤ï¼‰"), num_cols)
                group_col = st.selectbox(get_localized_text("ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰"), cat_cols)

            with col2:
                agg_options = [
                    get_localized_text('å¹³å‡'),
                    get_localized_text('åˆè¨ˆ'),
                    get_localized_text('ä¸­å¤®å€¤'),
                    get_localized_text('æœ€å¤§'),
                    get_localized_text('æœ€å°'),
                    get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°')
                ]
                selected_aggs_display = st.multiselect(
                    get_localized_text("è¡¨ç¤ºã™ã‚‹çµ±è¨ˆæŒ‡æ¨™"),
                    agg_options,
                    default=agg_options
                )
                exclude_outliers = st.checkbox(get_localized_text("å¤–ã‚Œå€¤ã‚’é™¤å¤–"))

            try:
                analysis_df = df.copy()
                
                if exclude_outliers and target_num in analysis_df.columns and analysis_df[target_num].std() > 0:
                    z_scores = np.abs((analysis_df[target_num] - analysis_df[target_num].mean()) / 
                                    analysis_df[target_num].std())
                    analysis_df = analysis_df[z_scores < 3]
                elif exclude_outliers: # std=0ã®å ´åˆ
                    st.info(get_localized_text(
                        f"'{target_num}'ã®ãƒ‡ãƒ¼ã‚¿ã«ã°ã‚‰ã¤ããŒãªã„ãŸã‚ã€å¤–ã‚Œå€¤é™¤å¤–ã¯é©ç”¨ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
                    ))


                agg_map_internal = {
                    get_localized_text('å¹³å‡'): 'mean',
                    get_localized_text('åˆè¨ˆ'): 'sum',
                    get_localized_text('ä¸­å¤®å€¤'): 'median',
                    get_localized_text('æœ€å¤§'): 'max',
                    get_localized_text('æœ€å°'): 'min',
                    get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°'): 'count'
                }
                
                agg_funcs_list = [agg_map_internal[a] for a in selected_aggs_display if a in agg_map_internal] 

                if group_col in analysis_df.columns and target_num in analysis_df.columns:
                    grouped_df = analysis_df.groupby(group_col)[target_num].agg(agg_funcs_list)
                    
                    # å­˜åœ¨ã™ã‚‹ã‚«ãƒ©ãƒ ã®ã¿ãƒªãƒãƒ¼ãƒ 
                    rename_dict = {agg_map_internal[a]: f"{target_num}_{a}" for a in selected_aggs_display if agg_map_internal[a] in grouped_df.columns}
                    grouped_df.rename(columns=rename_dict, inplace=True)

                else:
                    st.error(get_localized_text("é¸æŠã•ã‚ŒãŸåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚"))
                    grouped_df = pd.DataFrame()

                if not grouped_df.empty:
                    st.markdown(get_localized_text("### ğŸ“Š ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥é›†è¨ˆçµæœ"))
                    st.dataframe(grouped_df.round(2), use_container_width=True)

                    if selected_aggs_display:
                        st.markdown(get_localized_text("### ğŸ“ˆ çµ±è¨ˆæŒ‡æ¨™åˆ¥ã‚°ãƒ©ãƒ•"))
                        cols = st.columns(2)
                        for i, metric_display_name in enumerate(selected_aggs_display):
                            col_name_for_plot = f"{target_num}_{metric_display_name}" 
                            if col_name_for_plot in grouped_df.columns:
                                with cols[i % 2]:
                                    fig, ax = plt.subplots(figsize=(8, 4))
                                    # ğŸ”½ ã“ã‚Œã‚’è¿½åŠ ï¼ˆxè»¸ã®ãƒ©ãƒ™ãƒ«ã«æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨ï¼‰
                                    plt.draw()
                                    for label in ax.get_xticklabels():
                                        label.set_fontproperties(font_prop)

                                    grouped_df[col_name_for_plot].plot(kind='bar', ax=ax)
                                    # Apply font_prop to title, labels, and ticks
                                    ax.set_ylabel(get_graph_text(f"{target_num}ã®{metric_display_name}"), fontproperties=font_prop)
                                    ax.set_xlabel(get_graph_text(group_col), fontproperties=font_prop)
                                    ax.set_title(get_graph_text(f"{group_col}ã”ã¨ã®{target_num}ï¼ˆ{metric_display_name}ï¼‰"), fontproperties=font_prop)
                                    for label in ax.get_xticklabels():
                                        label.set_fontproperties(font_prop)
                                    for label in ax.get_yticklabels():
                                        label.set_fontproperties(font_prop)
                                    plt.xticks(rotation=45)
                                    plt.tight_layout()
                                    st.pyplot(fig)

                                    buf = io.BytesIO()
                                    fig.savefig(buf, format='png')
                                    st.download_button(
                                        get_localized_text(f"ğŸ“¥ {metric_display_name}ã®ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜"),
                                        buf.getvalue(),
                                        f"analysis_{metric_display_name}.png",
                                        "image/png"
                                    )
                else:
                    st.warning(get_localized_text("é›†è¨ˆçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"))

            except Exception as e:
                st.error(get_localized_text(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}"))
        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))

    with tabs[2]:
        st.header(get_localized_text("ğŸ“Š ã‚¯ãƒ­ã‚¹é›†è¨ˆ"))

        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()

            cat_cols = df.select_dtypes(include='object').columns.tolist()
            num_cols = df.select_dtypes(include='number').columns.tolist()

            if len(cat_cols) < 2:
                st.warning(get_localized_text("ã‚¯ãƒ­ã‚¹é›†è¨ˆã«ã¯2ã¤ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒå¿…è¦ã§ã™ã€‚"))
                st.stop()
            if not num_cols:
                st.warning(get_localized_text("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                st.stop()

            col1 = st.selectbox(get_localized_text("è¡Œã‚«ãƒ†ã‚´ãƒª"), cat_cols, key="cross_row")
            col2_options = [c for c in cat_cols if c != col1]
            if not col2_options:
                st.warning(get_localized_text(f"'{col1}' ä»¥å¤–ã®ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                st.stop()
            col2 = st.selectbox(get_localized_text("åˆ—ã‚«ãƒ†ã‚´ãƒª"), col2_options, key="cross_col")

            num_col = st.selectbox(get_localized_text("æ•°å€¤é …ç›®"), num_cols, key="cross_num")
            agg_method_display = st.selectbox(get_localized_text("é›†è¨ˆæ–¹æ³•"), [
                get_localized_text('å¹³å‡'),
                get_localized_text('åˆè¨ˆ'),
                get_localized_text('ä¸­å¤®å€¤'),
                get_localized_text('æœ€å¤§'),
                get_localized_text('æœ€å°'),
                get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°')
            ], key="cross_agg")

            if st.button(get_localized_text("ã‚¯ãƒ­ã‚¹é›†è¨ˆã‚’å®Ÿè¡Œ"), key="cross_execute"):
                try:
                    agg_map_internal = {
                        get_localized_text('å¹³å‡'): 'mean',
                        get_localized_text('åˆè¨ˆ'): 'sum',
                        get_localized_text('ä¸­å¤®å€¤'): 'median',
                        get_localized_text('æœ€å¤§'): 'max',
                        get_localized_text('æœ€å°'): 'min',
                        get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°'): 'count'
                    }

                    if col1 in df.columns and col2 in df.columns and num_col in df.columns:
                        cross_table = pd.pivot_table(
                            df,
                            values=num_col,
                            index=col1,
                            columns=col2,
                            aggfunc=agg_map_internal[agg_method_display]
                        )
                        if isinstance(cross_table.columns, pd.MultiIndex):
                            cross_table.columns = cross_table.columns.droplevel(0)

                        st.dataframe(cross_table)

                        fig, ax = plt.subplots(figsize=(10, 5))
                        cross_table.plot(kind='bar', ax=ax)
                        # Apply font_prop to title, labels, and ticks
                        ax.set_ylabel(get_graph_text(num_col), fontproperties=font_prop) # Column name is fine
                        ax.set_xlabel(get_graph_text(col1), fontproperties=font_prop)
                        ax.set_title(get_graph_text(f"{col1} Ã— {col2} ã® {agg_method_display}"), fontproperties=font_prop)
                        for label in ax.get_xticklabels():
                            label.set_fontproperties(font_prop)
                        for label in ax.get_yticklabels():
                            label.set_fontproperties(font_prop)
                        plt.xticks(rotation=45)
                        plt.tight_layout()
                        st.pyplot(fig)

                        csv = cross_table.to_csv(encoding='utf-8-sig').encode('utf-8-sig')
                        st.download_button(
                            get_localized_text("ğŸ“¥ ã‚¯ãƒ­ã‚¹é›†è¨ˆçµæœã‚’CSVã§ä¿å­˜"),
                            csv,
                            file_name="cross_table.csv",
                            mime='text/csv',
                            key="cross_download"
                        )
                    else:
                        st.error(get_localized_text("é¸æŠã•ã‚ŒãŸåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚"))

                except Exception as e:
                    st.error(get_localized_text(f"ã‚¯ãƒ­ã‚¹é›†è¨ˆã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"))
        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))


    with tabs[3]:
        st.header(get_localized_text("ğŸŸ¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"))

        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()

            df = DataProcessor.expand_time_slots(df)

            if 'æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ' not in df.columns or 'æ›œæ—¥' not in df.columns:
                st.warning(get_localized_text("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹ã«ã¯ã€Œæ™‚é–“å¸¯ã€ã¨ã€Œæ›œæ—¥ã€ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚"))
                st.stop()
            
            if not all(col in df.columns for col in ['æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ', 'æ›œæ—¥']):
                st.warning(get_localized_text("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ä½œæˆã«å¿…è¦ãªåˆ—ï¼ˆæ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆã€æ›œæ—¥ï¼‰ãŒãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚"))
                st.stop()


            numeric_cols = df.select_dtypes(include='number').columns.tolist()
            if not numeric_cols:
                st.warning(get_localized_text("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚"))
                st.stop()

            col1, col2 = st.columns(2)
            with col1:
                heat_metric = st.selectbox(
                    get_localized_text("é›†è¨ˆã™ã‚‹æŒ‡æ¨™"),
                    numeric_cols,
                    key="heat_metric"
                )
                agg_method_display = st.selectbox(
                    get_localized_text("é›†è¨ˆæ–¹æ³•"),
                    [get_localized_text('å¹³å‡'), get_localized_text('åˆè¨ˆ'), get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°')],
                    key="heat_agg"
                )

            with col2:
                color_scale = st.selectbox(
                    get_localized_text("ã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«"),
                    ['YlOrRd', 'viridis', 'coolwarm'],
                    key="heat_color"
                )
                normalize = st.checkbox(get_localized_text("ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–"), value=True, key="heat_normalize")

            if st.button(get_localized_text("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆ"), key="heat_execute"):
                try:
                    heat_df = df.copy()

                    agg_map_internal = {
                        get_localized_text('å¹³å‡'): 'mean',
                        get_localized_text('åˆè¨ˆ'): 'sum',
                        get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°'): 'count'
                    }
                    pivot_table = pd.pivot_table(
                        heat_df,
                        values=heat_metric,
                        index='æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ',
                        columns='æ›œæ—¥',
                        aggfunc=agg_map_internal[agg_method_display]
                        )

                    weekdays = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
                    existing_weekdays = [day for day in weekdays if day in pivot_table.columns]
                    pivot_table = pivot_table.reindex(columns=existing_weekdays)
                    
                    try:
                        pivot_table = pivot_table.reindex(sorted(pivot_table.index))
                    except Exception:
                        pass

                    if normalize and not pivot_table.empty and pivot_table.std().std() > 0:
                        pivot_table = (pivot_table - pivot_table.mean().mean()) / pivot_table.std().std()
                    elif normalize and not pivot_table.empty: # æ¨™æº–åå·®ãŒ0ã®å ´åˆ
                        st.info(get_localized_text("ãƒ‡ãƒ¼ã‚¿ã«ã°ã‚‰ã¤ããŒãªã„ãŸã‚ã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®æ­£è¦åŒ–ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚"))


                    fig, ax = plt.subplots(figsize=(12, 8))
                    sns.heatmap(
                        pivot_table,
                        cmap=color_scale,
                        annot=True,
                        fmt='.2f',
                        linewidths=.5,
                        linecolor='black',
                        ax=ax
                    )

                    # Apply font_prop to title, labels, and ticks
                    ax.set_title(get_graph_text(f"æ™‚é–“å¸¯Ã—æ›œæ—¥ã®{heat_metric}ï¼ˆ{agg_method_display}ï¼‰"), fontproperties=font_prop, fontsize=16)
                    ax.set_xlabel(get_graph_text(str("æ›œæ—¥")), fontproperties=font_prop, fontsize=12)
                    ax.set_ylabel(get_graph_text("æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ"), fontproperties=font_prop, fontsize=12)
                    ax.set_xticklabels(ax.get_xticklabels(), fontproperties=font_prop)
                    ax.set_yticklabels(ax.get_yticklabels(), fontproperties=font_prop)

                    for label in ax.get_xticklabels():
                        label.set_fontproperties(font_prop)
                    for label in ax.get_yticklabels():
                        label.set_fontproperties(font_prop)

                    plt.xticks(rotation=45)
                    plt.tight_layout()
                    st.pyplot(fig)

                    csv = pivot_table.to_csv(encoding='utf-8-sig').encode('utf-8-sig')
                    st.download_button(
                        get_localized_text("ğŸ“¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜"),
                        csv,
                        file_name="heatmap_data.csv",
                        mime='text/csv',
                        key="heat_download"
                    )

                    st.subheader(get_localized_text("ğŸ“Š ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³"))

                    if not pivot_table.empty:
                        max_val_series = pivot_table.max()
                        if not max_val_series.empty:
                            max_val = max_val_series.max()
                        else:
                            max_val = np.nan

                        min_val_series = pivot_table.min()
                        if not min_val_series.empty:
                            min_val = min_val_series.min()
                        else:
                            min_val = np.nan

                        if not np.isnan(max_val) and not pivot_table[pivot_table == max_val].empty:
                            max_pos_df = pivot_table[pivot_table == max_val].stack().index[0]
                            st.info(get_localized_text(
                                f"ğŸ”º æœ€ã‚‚{heat_metric}ãŒé«˜ã„æ™‚é–“å¸¯: {max_pos_df[0]}ã®{max_pos_df[1]}æ›œæ—¥ ({max_val:.2f})"
                            ))
                        else:
                            st.info(get_localized_text("ğŸ”º æœ€ã‚‚é«˜ã„å€¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"))

                        if not np.isnan(min_val) and not pivot_table[pivot_table == min_val].empty:
                            min_pos_df = pivot_table[pivot_table == min_val].stack().index[0]
                            st.info(get_localized_text(
                                f"ğŸ”» æœ€ã‚‚{heat_metric}ãŒä½ã„æ™‚é–“å¸¯: {min_pos_df[0]}ã®{min_pos_df[1]}æ›œæ—¥ ({min_val:.2f})"
                            ))
                        else:
                            st.info(get_localized_text("ğŸ”» æœ€ã‚‚ä½ã„å€¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"))
                    else:
                        st.info(get_localized_text("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã€‚"))


                except Exception as e:
                    st.error(get_localized_text(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}"))
        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))


    with tabs[4]:
        st.header(get_localized_text("ğŸ“‰ æ™‚ç³»åˆ—åˆ†æ"))

        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()

            if 'å®Ÿæ–½æ—¥' not in df.columns:
                st.warning(get_localized_text("æ™‚ç³»åˆ—åˆ†æã«ã¯ã€Œå®Ÿæ–½æ—¥ã€ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚"))
                st.stop()
            
            # å®Ÿæ–½æ—¥ãŒPythonã®dateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€ãã®ã¾ã¾dropna
            df = df.dropna(subset=['å®Ÿæ–½æ—¥'])

            if df.empty:
                st.warning(get_localized_text("æœ‰åŠ¹ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                st.stop()

            # DatetimeIndexã®ä½œæˆç”¨ã«ã€dateã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’Timestampã«å¤‰æ›
            df['å®Ÿæ–½æ—¥_timestamp'] = pd.to_datetime(df['å®Ÿæ–½æ—¥'])


            cat_cols = df.select_dtypes(include='object').columns.tolist()
            numeric_cols = df.select_dtypes(include='number').columns.tolist()

            if not numeric_cols:
                st.warning(get_localized_text("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ™‚ç³»åˆ—åˆ†æã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚"))
                st.stop()

            col1, col2 = st.columns(2)
            with col1:
                trend_metric = st.selectbox(
                    get_localized_text("åˆ†æã™ã‚‹æŒ‡æ¨™"),
                    numeric_cols,
                    key="trend_metric"
                )
                trend_group = st.selectbox(
                    get_localized_text("ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"),
                    ['ãªã—'] + cat_cols,
                    key="trend_group"
                )

            with col2:
                agg_period_display = st.selectbox(
                    get_localized_text("é›†è¨ˆæœŸé–“"),
                    [get_localized_text('æ—¥æ¬¡'), get_localized_text('é€±æ¬¡'), get_localized_text('æœˆæ¬¡')],
                    key="trend_period"
                )
                moving_avg = st.number_input(
                    get_localized_text("ç§»å‹•å¹³å‡æœŸé–“"), 
                    min_value=1,
                    max_value=30,
                    value=7,
                    key="trend_ma"
                )

            try:
                trend_df = df.copy()
                
                period_map_internal = {
                    get_localized_text('æ—¥æ¬¡'): 'D',
                    get_localized_text('é€±æ¬¡'): 'W',
                    get_localized_text('æœˆæ¬¡'): 'M'
                }

                fig, ax = plt.subplots(figsize=(12, 6))
                has_data_to_plot = False 

                if trend_group == 'ãªã—':
                    resampled = trend_df.set_index('å®Ÿæ–½æ—¥_timestamp')[trend_metric].resample(period_map_internal[agg_period_display]).mean()
                    
                    if not resampled.empty:
                        resampled.plot(ax=ax, label=get_graph_text(f'{agg_period_display}å¹³å‡'), fontproperties=font_prop)
                        moving = resampled.rolling(window=moving_avg, min_periods=1).mean() 
                        if not moving.empty:
                            moving.plot(ax=ax, label=get_graph_text(f'{moving_avg}{agg_period_display[0]}ç§»å‹•å¹³å‡'), style='--', fontproperties=font_prop) 
                        else:
                            st.info(get_localized_text("ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                        has_data_to_plot = True
                    else:
                        st.warning(get_localized_text("é›†è¨ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"))
                    
                    if not resampled.empty:
                        st.subheader(get_localized_text("ğŸ“Š æ™‚ç³»åˆ—ã®ç‰¹å¾´"))
                        latest_val = resampled.iloc[-1]
                        prev_val = resampled.iloc[-2] if len(resampled) > 1 else None

                        st.info(get_localized_text(f"æœ€æ–°ã®{agg_period_display}å¹³å‡: {latest_val:.2f}"))
                        if prev_val is not None and prev_val != 0:
                            change = ((latest_val - prev_val) / prev_val * 100)
                            st.info(get_localized_text(f"ç›´è¿‘ã®{agg_period_display}ã‹ã‚‰ã®å¤‰åŒ–ç‡: {change:.1f}%"))
                        else:
                            st.info(get_localized_text("ç›´è¿‘ã®å¤‰åŒ–ç‡ã‚’è¨ˆç®—ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                    else:
                        st.info(get_localized_text("é›†è¨ˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ç‰¹å¾´ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã€‚"))

                    if not resampled.empty:
                        csv = resampled.to_csv(encoding='utf-8-sig').encode('utf-8-sig')
                        st.download_button(
                            get_localized_text("ğŸ“¥ æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜"),
                            csv,
                            file_name="trend_data.csv",
                            mime='text/csv',
                            key="trend_download"
                        )

                else:
                    if trend_group in trend_df.columns:
                        groups = trend_df[trend_group].dropna().unique()
                        if len(groups) > 0:
                            for group in groups:
                                if pd.notna(group) and str(group).strip() != '':
                                    group_data = trend_df[trend_df[trend_group] == group]
                                    if not group_data.empty:
                                        resampled = group_data.set_index('å®Ÿæ–½æ—¥_timestamp')[trend_metric].resample(period_map_internal[agg_period_display]).mean()
                                        if not resampled.empty:
                                            resampled.plot(ax=ax, label=str(group), fontproperties=font_prop) # Group name is data, keep as is
                                            moving = resampled.rolling(window=moving_avg, min_periods=1).mean()
                                            if not moving.empty:
                                                moving.plot(ax=ax, label=get_graph_text(f'{str(group)} ({moving_avg}{agg_period_display[0]}ç§»å‹•å¹³å‡)'), style='--', fontproperties=font_prop) 
                                            else:
                                                st.info(get_localized_text(f"ã‚°ãƒ«ãƒ¼ãƒ— '{group}' ã®ç§»å‹•å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                                            has_data_to_plot = True
                                        else:
                                            st.warning(get_localized_text(f"ã‚°ãƒ«ãƒ¼ãƒ— '{group}' ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"))
                                    else:
                                        st.warning(get_localized_text(f"ã‚°ãƒ«ãƒ¼ãƒ— '{group}' ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                            
                            if not has_data_to_plot:
                                st.warning(get_localized_text("é¸æŠã•ã‚ŒãŸã‚°ãƒ«ãƒ¼ãƒ—ã®ã„ãšã‚Œã‚‚æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"))
                        else:
                            st.warning(get_localized_text(f"é¸æŠã•ã‚ŒãŸã‚°ãƒ«ãƒ¼ãƒ—åˆ— '{trend_group}' ã«æœ‰åŠ¹ãªå€¤ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                    else:
                        st.error(get_localized_text(f"é¸æŠã•ã‚ŒãŸã‚°ãƒ«ãƒ¼ãƒ—åˆ— '{trend_group}' ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚"))

                if has_data_to_plot:
                    # Apply font_prop to title, labels, and legend
                    ax.set_title(get_graph_text(
                        f"{trend_metric}ã®æ™‚ç³»åˆ— ({'å…¨ä½“' if trend_group == 'ãªã—' else trend_group}åˆ¥)"
                    ), fontproperties=font_prop, fontsize=16)
                    ax.set_xlabel(get_graph_text(str("å®Ÿæ–½æ—¥")), fontproperties=font_prop, fontsize=12)
                    ax.set_ylabel(get_graph_text(f"{trend_metric} ({agg_period_display}å¹³å‡)"), fontproperties=font_prop, fontsize=12)
                    ax.legend(prop=font_prop) # Use font_prop directly for legend
                    ax.set_xticklabels(ax.get_xticklabels(), fontproperties=font_prop)
                    ax.set_yticklabels(ax.get_yticklabels(), fontproperties=font_prop)
                    for label in ax.get_xticklabels():
                        label.set_fontproperties(font_prop)
                    for label in ax.get_yticklabels():
                        label.set_fontproperties(font_prop)
                    plt.tight_layout()
                    st.pyplot(fig)
                else:
                    plt.close(fig) 


            except Exception as e:
                st.error(get_localized_text(f"æ™‚ç³»åˆ—åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}"))
        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))


    with tabs[5]:
        st.header(get_localized_text("ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æ"))

        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()

            numeric_cols = df.select_dtypes(include='number').columns.tolist()
            cat_cols = df.select_dtypes(include='object').columns.tolist()

            if not numeric_cols:
                st.warning(get_localized_text("æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                st.stop()
            if not cat_cols:
                st.warning(get_localized_text("ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
                st.stop()

            col1, col2 = st.columns(2)
            with col1:
                rank_metric = st.selectbox(
                    get_localized_text("ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æŒ‡æ¨™"), 
                    numeric_cols,
                    key="rank_metric"
                )
                rank_group = st.selectbox(
                    get_localized_text("ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"),
                    cat_cols,
                    key="rank_group"
                )

            with col2:
                top_n = st.number_input(
                    get_localized_text("è¡¨ç¤ºä»¶æ•°"),
                    min_value=1,
                    max_value=50,
                    value=10,
                    key="rank_topn"
                )
                ascending_option = st.radio(
                    get_localized_text("ä¸¦ã³é †"),
                    [get_localized_text("é™é †ï¼ˆå¤§ãã„é †ï¼‰"), get_localized_text("æ˜‡é †ï¼ˆå°ã•ã„é †ï¼‰")],
                    index=0,
                    key="rank_order"
                )

            if st.button(get_localized_text("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º"), key="rank_execute"):
                try:
                    if rank_group not in df.columns or rank_metric not in df.columns:
                        st.error(get_localized_text("é¸æŠã•ã‚ŒãŸåˆ—ãŒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚"))
                        st.stop()

                    rank_df = df.groupby(rank_group)[rank_metric].agg(['mean', 'count']).round(2)
                    rank_df.columns = [get_localized_text('å¹³å‡å€¤'), get_localized_text('ãƒ‡ãƒ¼ã‚¿æ•°')]
                    rank_df = rank_df.sort_values(
                        get_localized_text('å¹³å‡å€¤'),
                        ascending=(ascending_option == get_localized_text("æ˜‡é †ï¼ˆå°ã•ã„é †ï¼‰"))
                    )

                    st.subheader(get_localized_text("ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ"))
                    rank_display = rank_df.head(top_n).copy()
                    rank_display.index.name = rank_group
                    st.dataframe(rank_display)

                    fig, ax = plt.subplots(figsize=(10, max(5, top_n * 0.3)))
                    rank_display[get_localized_text('å¹³å‡å€¤')].plot(kind='barh', ax=ax)
                    # Apply font_prop to title, labels, and ticks
                    ax.set_title(get_graph_text(f"{rank_group}åˆ¥ {rank_metric}ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°"), fontproperties=font_prop, fontsize=16)
                    ax.set_xlabel(get_graph_text(str(f"{rank_metric} å¹³å‡å€¤")), fontproperties=font_prop, fontsize=12)
                    ax.set_ylabel(get_graph_text(rank_group), fontproperties=font_prop, fontsize=12) # Group name is data, keep as is
                    ax.set_xticklabels(ax.get_xticklabels(), fontproperties=font_prop)
                    ax.set_yticklabels(ax.get_yticklabels(), fontproperties=font_prop)
                    ax.set_xlabel(get_graph_text(str(f"{rank_metric} å¹³å‡å€¤")), fontproperties=font_prop)

                    for label in ax.get_xticklabels():
                        label.set_fontproperties(font_prop)
                    for label in ax.get_yticklabels():
                        label.set_fontproperties(font_prop)

                    plt.tight_layout()
                    st.pyplot(fig)

                    csv = rank_display.to_csv(encoding='utf-8-sig').encode('utf-8-sig')
                    st.download_button(
                        get_localized_text("ğŸ“¥ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ä¿å­˜"),
                        csv,
                        file_name="ranking_data.csv",
                        mime='text/csv',
                        key="rank_download"
                    )

                    st.subheader(get_localized_text("ğŸ“ˆ ç‰¹å¾´çš„ãªãƒ‡ãƒ¼ã‚¿"))

                    if not rank_display.empty:
                        top_item = rank_display.index[0]
                        top_val = rank_display.loc[top_item, get_localized_text('å¹³å‡å€¤')]
                        st.info(get_localized_text(
                            f"ğŸ† ãƒˆãƒƒãƒ—ã®{rank_group}: {top_item} ({top_val:.2f})"
                        ))

                        if len(rank_display) > 1:
                            second_item = rank_display.index[1]
                            second_val = rank_display.loc[second_item, get_localized_text('å¹³å‡å€¤')]
                            if pd.notna(top_val) and pd.notna(second_val):
                                diff = top_val - second_val
                                if second_val != 0:
                                    st.info(get_localized_text(
                                        f"2ä½ã¨ã®å·®: {diff:.2f} ({(diff/second_val*100):.1f}%)"
                                    ))
                                else:
                                    st.info(get_localized_text(
                                        f"2ä½ã¨ã®å·®: {diff:.2f} (2ä½ã®å€¤ãŒ0ã®ãŸã‚å¤‰åŒ–ç‡ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“)"
                                    ))
                            else:
                                st.info(get_localized_text("ãƒˆãƒƒãƒ—ã¾ãŸã¯2ä½ã®å€¤ãŒæ¬ æã—ã¦ã„ã‚‹ãŸã‚ã€å·®ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚"))
                    else:
                        st.info(get_localized_text("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ç‰¹å¾´çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã€‚"))

                except Exception as e:
                    st.error(get_localized_text(f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}"))
        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))

    with tabs[6]:
        st.header(get_localized_text("ğŸ“‹ è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆ"))

        if 'current_data' in st.session_state and st.session_state.current_data is not None and not st.session_state.current_data.empty:
            df = st.session_state.current_data.copy()

            if 'å‚åŠ ç‡(%)' not in df.columns and 'ç”³è¾¼æ•°' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                df['å‚åŠ ç‡(%)'] = (df['å‚åŠ è€…æ•°'] / df['ç”³è¾¼æ•°']) * 100
            if 'æº€è¶³ç‡(%)' not in df.columns and 'æº€è¶³å›ç­”' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                df['æº€è¶³ç‡(%)'] = (df['æº€è¶³å›ç­”'] / df['å‚åŠ è€…æ•°']) * 100
            # ä¿®æ­£: 'not in in' ã‚’ 'not in' ã«å¤‰æ›´
            if 'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡' not in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                df['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡'] = df['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°'] / df['å‚åŠ è€…æ•°']

            df = DataProcessor.expand_time_slots(df)

            st.subheader(get_localized_text("ğŸ“£ å‚åŠ è€…æ•°ã‚’å¢—ã‚„ã™ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åˆ†æ"))

            def append_section_to_report(title_jp, df_to_use):
                st.markdown(get_localized_text(f"#### {title_jp}"))
                st.dataframe(df_to_use, use_container_width=True) # use_container_width=True ã‚’è¿½åŠ 


            st.markdown(get_localized_text("### ğŸ† ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¾ã¨ã‚"))
            if 'æ‹…å½“ãƒãƒ¼ãƒ ' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                team_avg = df.groupby("æ‹…å½“ãƒãƒ¼ãƒ ")["å‚åŠ è€…æ•°"].mean().sort_values(ascending=False).reset_index()
                append_section_to_report("å‚åŠ è€…æ•°ãŒå¤šã„ãƒãƒ¼ãƒ ", team_avg)
            else:
                st.info(get_localized_text("ã€Œæ‹…å½“ãƒãƒ¼ãƒ ã€ã¾ãŸã¯ã€Œå‚åŠ è€…æ•°ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))

            if 'æ›œæ—¥' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                weekday_avg = df.groupby("æ›œæ—¥")["å‚åŠ è€…æ•°"].mean().sort_values(ascending=False).reindex(index=['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']).dropna().reset_index()
                append_section_to_report("æ›œæ—¥åˆ¥ã®å‚åŠ è€…æ•°", weekday_avg)
            else:
                st.info(get_localized_text("ã€Œæ›œæ—¥ã€ã¾ãŸã¯ã€Œå‚åŠ è€…æ•°ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))

            if 'æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                time_avg = df.groupby("æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ")["å‚åŠ è€…æ•°"].mean().sort_values(ascending=False).reset_index()
                append_section_to_report("æ™‚é–“å¸¯åˆ¥ã®å‚åŠ è€…æ•°", time_avg)
            else:
                st.info(get_localized_text("ã€Œæ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆã€ã¾ãŸã¯ã€Œå‚åŠ è€…æ•°ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))


            if 'å‚åŠ ç‡(%)' in df.columns:
                cols_for_top_rate = [col for col in ["ã‚¤ãƒ™ãƒ³ãƒˆå", "æ›œæ—¥", "æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ", "å‚åŠ ç‡(%)"] if col in df.columns]
                top_rate = df.sort_values("å‚åŠ ç‡(%)", ascending=False).head(5)[cols_for_top_rate].reset_index(drop=True)
                top_rate.index += 1
                append_section_to_report("å‚åŠ ç‡ãŒé«˜ã„ã‚¤ãƒ™ãƒ³ãƒˆ", top_rate)
            else:
                st.info(get_localized_text("ã€Œå‚åŠ ç‡(%)ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))

            if 'æº€è¶³ç‡(%)' in df.columns:
                cols_for_top_satisfaction = [col for col in ["ã‚¤ãƒ™ãƒ³ãƒˆå", "æ›œæ—¥", "æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆ", "æº€è¶³ç‡(%)"] if col in df.columns]
                top_satisfaction = df.sort_values("æº€è¶³ç‡(%)", ascending=False).head(5)[cols_for_top_satisfaction].reset_index(drop=True)
                top_satisfaction.index += 1
                append_section_to_report("æº€è¶³åº¦ãŒé«˜ã„ã‚¤ãƒ™ãƒ³ãƒˆ", top_satisfaction)
            else:
                st.info(get_localized_text("ã€Œæº€è¶³ç‡(%)ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))

            if 'æ›œæ—¥' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                low_participation_raw = df.groupby("æ›œæ—¥")["å‚åŠ è€…æ•°"].mean().sort_values().reset_index()
                low_participation = low_participation_raw.head(3).copy()
                low_participation.index += 1
                append_section_to_report("å‚åŠ è€…æ•°ãŒå°‘ãªã„æ›œæ—¥", low_participation)
            else:
                st.info(get_localized_text("ã€Œæ›œæ—¥ã€ã¾ãŸã¯ã€Œå‚åŠ è€…æ•°ã€ã®åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))

            st.markdown(get_localized_text("### ğŸ’¡ å®£ä¼ãƒ»ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨å‚åŠ è€…æ•°ã®é–¢ä¿‚"))
            
            corr_summary_text = []
            if 'å®£ä¼å›æ•°' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                corr1 = df['å‚åŠ è€…æ•°'].corr(df['å®£ä¼å›æ•°'])
                if pd.notna(corr1):
                    corr_summary_text.append(get_localized_text(f"ã€Œå®£ä¼å›æ•°ã€ã¨ã€Œå‚åŠ è€…æ•°ã€ã®ç›¸é–¢: {corr1:.2f}"))
                else:
                    corr_summary_text.append(get_localized_text("ã€Œå®£ä¼å›æ•°ã€ã¨ã€Œå‚åŠ è€…æ•°ã€ã®ç›¸é–¢ã¯è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯å®šæ•°ï¼‰ã€‚"))
            else:
                corr_summary_text.append(get_localized_text("ã€Œå®£ä¼å›æ•°ã€ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"))

            if 'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡' in df.columns and 'å‚åŠ è€…æ•°' in df.columns:
                corr2 = df['å‚åŠ è€…æ•°'].corr(df['ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡'])
                if pd.notna(corr2):
                    corr_summary_text.append(get_localized_text(f"ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡ã€ã¨ã€Œå‚åŠ è€…æ•°ã€ã®ç›¸é–¢: {corr2:.2f}"))
                else:
                    corr_summary_text.append(get_localized_text("ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡ã€ã¨ã€Œå‚åŠ è€…æ•°ã€ã®ç›¸é–¢ã¯è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ã¾ãŸã¯å®šæ•°ï¼‰ã€‚"))
            else:
                st.info(get_localized_text("ã€Œãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç‡ã€ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"))
            
            for line in corr_summary_text:
                st.info(line)


        else:
            st.warning(get_localized_text("ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"))


# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ ---
def main():
    # Streamlitã®ãƒšãƒ¼ã‚¸è¨­å®šã¯ä¸€åº¦ã ã‘è¡Œã†
    st.set_page_config(page_title=get_localized_text("VRã‚¤ãƒ™ãƒ³ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«"), layout="wide")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«logged_inãŒãªã‘ã‚Œã°åˆæœŸåŒ–ï¼ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ã®ã¿Falseã«è¨­å®šï¼‰
    if "logged_in" not in st.session_state:
        st.session_state["logged_in"] = False

    if st.session_state.get("logged_in"):
        # ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã®å ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’è¡¨ç¤ºã—ã€ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã¨ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚’è¡¨ç¤º
        st.sidebar.markdown(get_localized_text(f"**ã‚ˆã†ã“ãã€{st.session_state.get('username')} ã•ã‚“ï¼**"))
        if st.sidebar.button(get_localized_text("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ")):
            # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆå‡¦ç†
            for key in ["logged_in", "username", "num_uploaders"]: # num_uploadersã‚‚ã‚¯ãƒªã‚¢
                st.session_state.pop(key, None)
            st.rerun()
        show_main_app()
    else:
        # æœªãƒ­ã‚°ã‚¤ãƒ³ã®å ´åˆã€ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
        login_form()

if __name__ == "__main__":
    main()
